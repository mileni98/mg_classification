{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import findspark\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType, FloatType, IntegerType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, PCA, StandardScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LinearSVC\n",
    "\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "TARGET_DIR_NAME = os.getenv(\"TARGET_DIR_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session running on 12 cores. UI is available at: http://DESKTOP-684SCQF:4050\n"
     ]
    }
   ],
   "source": [
    "findspark.init()\n",
    "\n",
    "# Initialize Spark session to run locally\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Big Data Classification\") \\\n",
    "    .config(\"spark.master\", \"local[*]\") \\\n",
    "    .config(\"spark.ui.port\", \"4050\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Print the number of cores being used by Spark\n",
    "print(f\"Spark Session running on {spark.sparkContext.defaultParallelism} cores. UI is available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions for infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: DataFrame) -> DataFrame:\n",
    "    \"\"\"Preprocess the data by removing rows with NaN values.\"\"\"    \n",
    "\n",
    "    # Remove rows with NaN values and count the number of rows before and after\n",
    "    total_rows_before = data.count()\n",
    "    clean_data = data.dropna()\n",
    "    total_rows_after = clean_data.count()\n",
    "\n",
    "    if total_rows_before != total_rows_after:\n",
    "        print(f\"Number of rows with NaN values: {total_rows_before - total_rows_after}\")\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_patient_overlap(train_df: DataFrame, test_df: DataFrame, patient_column: str = 'patient', verbose_just_error: bool = False) -> None:\n",
    "    \"\"\"Checks for overlapping patients between train and test DataFrames.\"\"\"\n",
    "\n",
    "    # Get unique patients from train and test DataFrames\n",
    "    train_patients = train_df.select(patient_column).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    test_patients = test_df.select(patient_column).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    # Convert lists to sets and check for any overlap\n",
    "    overlapping_patients = set(train_patients).intersection(set(test_patients))\n",
    "\n",
    "    # Print overlapping patients, if any\n",
    "    if overlapping_patients:\n",
    "        print(f\"Overlapping patients found: {overlapping_patients}\")\n",
    "    elif not verbose_just_error:\n",
    "        print(\"No overlapping patients between training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_distribution(df1: DataFrame, df2: DataFrame, class_column: str = 'class') -> None:\n",
    "    \"\"\"Calculates and prints class distribution percentages for two DataFrames in a single line.\"\"\"\n",
    "    \n",
    "    # Calculate class counts for both DataFrames\n",
    "    df1_counts = df1.groupBy(class_column).count().orderBy(class_column).collect()\n",
    "    df2_counts = df2.groupBy(class_column).count().orderBy(class_column).collect()\n",
    "    \n",
    "    # Calculate total counts\n",
    "    total_count_df1 = df1.count()\n",
    "    total_count_df2 = df2.count()\n",
    "    \n",
    "    # Prepare class distributions as strings\n",
    "    df1_distribution = ', '.join([f\"{row[class_column]}: {row['count']} ({(row['count'] / total_count_df1) * 100:.2f}%)\" for row in df1_counts])\n",
    "    df2_distribution = ', '.join([f\"{row[class_column]}: {row['count']} ({(row['count'] / total_count_df2) * 100:.2f}%)\" for row in df2_counts])\n",
    "    \n",
    "    # Print class distributions in one line\n",
    "    print(f\"Class distribution in train_df: [{df1_distribution}] | test_df: [{df2_distribution}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_patient(data: DataFrame, test_ratio: float = 0.2, patient_column: str = 'patient', seed: int = 42) -> tuple[DataFrame, DataFrame]:\n",
    "    \"\"\" Splits the DataFrame into train and test sets based on unique patient IDs, ensuring no patient data overlap.\"\"\"\n",
    "\n",
    "    random.seed(seed) # Set seed for reproducibility\n",
    "    \n",
    "    # Extract unique patient IDs and randomly shuffle them\n",
    "    unique_patients = data.select(patient_column).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    random.shuffle(unique_patients)\n",
    "    \n",
    "    # Split the patients into train and test sets\n",
    "    split_index = int(len(unique_patients) * (1 - test_ratio))\n",
    "    train_patients = unique_patients[:split_index]\n",
    "    test_patients = unique_patients[split_index:]\n",
    "    \n",
    "    # Create train and test DataFrames \n",
    "    train_df = data.filter(col(patient_column).isin(train_patients))\n",
    "    test_df = data.filter(col(patient_column).isin(test_patients))\n",
    "    check_patient_overlap(train_df, test_df)\n",
    "    \n",
    "    # Calculate and print the percentages of train and test sets\n",
    "    total_rows, train_rows, test_rows = data.count(), train_df.count(), test_df.count()\n",
    "    print(f\"Training size: {train_rows} ({(train_rows / total_rows) * 100:.2f}%), Test size: {test_rows} rows ({(test_rows / total_rows) * 100:.2f}%)\") \n",
    "    \n",
    "    calculate_class_distribution(train_df, test_df)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds_by_patient(data: DataFrame, num_folds: int = 5, patient_column: str = 'patient', seed: int = 42) -> list:\n",
    "    \"\"\"Splits the data into train-test folds based on unique patient IDs, ensuring no patient overlap across folds.\"\"\"\n",
    "\n",
    "    random.seed(seed) # Set seed for reproducibility\n",
    "\n",
    "    # Extract unique patient IDs and randomly shuffle them\n",
    "    unique_patients = data.select(patient_column).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    random.shuffle(unique_patients)\n",
    "\n",
    "    # Split patients evenly into folds\n",
    "    fold_size = len(unique_patients) // num_folds\n",
    "    folds = [unique_patients[i * fold_size:(i + 1) * fold_size] for i in range(num_folds)]\n",
    "\n",
    "    # Handle any remaining patients by adding them to the last fold\n",
    "    for i in range(len(unique_patients) % num_folds):\n",
    "        folds[i].append(unique_patients[-(i + 1)])\n",
    "\n",
    "    patient_folds, fold_summaries = [], []\n",
    "\n",
    "    # Create train-test splits for each fold\n",
    "    total_rows = data.count()\n",
    "    for i in range(num_folds):\n",
    "\n",
    "        # Get the test patients for the current fold and assign the rest to the training set\n",
    "        test_patients = set(folds[i])\n",
    "        train_patients = set(unique_patients) - test_patients\n",
    "\n",
    "        # Filter the data based on the train and test patients\n",
    "        train_df = data.filter(col(patient_column).isin(train_patients))\n",
    "        test_df = data.filter(col(patient_column).isin(test_patients))\n",
    "        check_patient_overlap(train_df, test_df, verbose_just_error=True)\n",
    "\n",
    "        # Append the train-test split to the list of folds\n",
    "        patient_folds.append((train_df, test_df))\n",
    "\n",
    "        # Accumulate test set summary for this fold\n",
    "        fold_summaries.append(f\"Fold {i + 1}: {test_df.count()} rows ({(test_df.count() / total_rows) * 100:.2f}%)\")\n",
    "\n",
    "    print(\" | \".join(fold_summaries))\n",
    "\n",
    "    # Return the list of train-test tuples for each fold\n",
    "    return patient_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data: DataFrame, output_column: str = 'pca_features', k: int = 10) -> DataFrame:\n",
    "    \"\"\"Applies PCA to reduce the dimensionality of the feature set to k principal components.\"\"\"\n",
    "    \n",
    "    # Initialize PCA with the specified number of components\n",
    "    pca = PCA(k=k, inputCol='features', outputCol=output_column)\n",
    "    \n",
    "    # Fit PCA on the data and transform the features\n",
    "    pca_model = pca.fit(data)\n",
    "    transformed_data = pca_model.transform(data)\n",
    "    \n",
    "    print(f\"PCA explained variance ratio: {pca_model.explainedVariance.toArray()}\")\n",
    "    \n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_features(data: DataFrame, class_column: str = 'class', patient_column: str = 'patient', output_column: str = 'features', verbose: bool = True, standard_scaler: bool = False) -> DataFrame:\n",
    "    \"\"\"Assembles feature columns into a single feature vector column, excluding patient and class columns.\"\"\"\n",
    "    \n",
    "    # Get the numeric columns from the DataFrame\n",
    "    numeric_columns = [field.name for field in data.schema.fields if isinstance(field.dataType, (DoubleType, FloatType, IntegerType))]\n",
    "\n",
    "    # Define feature columns by excluding the numeric columns and the class and patient columns\n",
    "    feature_columns = [col for col in numeric_columns if col not in [class_column, patient_column, 'diagnostics_Mask-original_VoxelNum']]\n",
    "    #feature_columns = [col for col in numeric_columns if col not in [class_column, patient_column]]\n",
    "    if verbose:\n",
    "        print(f\"Number of initial columns: {len(data.columns)}, number of feature columns: {len(feature_columns)}\")\n",
    "    \n",
    "    # Assemble features into a feature vector\n",
    "    assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'assembled_features')\n",
    "    assembled_data = assembler.transform(data)\n",
    "\n",
    "    # Standardize features\n",
    "    if standard_scaler:\n",
    "        scaler = StandardScaler(inputCol=\"assembled_features\", outputCol = output_column, withStd = True, withMean = True)\n",
    "        scaler_model = scaler.fit(assembled_data)\n",
    "        scaled_data = scaler_model.transform(assembled_data)\n",
    "    else:\n",
    "        # Rename directly if no standardization is applied\n",
    "        assembled_data = assembled_data.withColumnRenamed('assembled_features', 'features')\n",
    "        scaled_data = assembled_data\n",
    "\n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions: DataFrame) -> tuple:\n",
    "    \"\"\"Calculates accuracy, precision, and recall from the predictions DataFrame.\"\"\"\n",
    "\n",
    "    # Calculate true positives, true negatives, false positives, and false negatives\n",
    "    tp = predictions.filter((col('prediction') == 1) & (col('class') == 1)).count()\n",
    "    tn = predictions.filter((col('prediction') == 0) & (col('class') == 0)).count()\n",
    "    fp = predictions.filter((col('prediction') == 1) & (col('class') == 0)).count()\n",
    "    fn = predictions.filter((col('prediction') == 0) & (col('class') == 1)).count()\n",
    "\n",
    "    # Calculate accuracy, precision, and recall\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_parameters_on_folds(model, train_df: DataFrame, paramGrid: list[dict], num_folds: int = 5, patient_column: str = 'patient', standard_scaler: bool = False):\n",
    "    \"\"\"Evaluates the Decision Tree model using patient-wise cross-validation with specified hyperparameter tuning.\"\"\"\n",
    "\n",
    "    folds = create_folds_by_patient(train_df, num_folds, patient_column)\n",
    "\n",
    "    # Use BinaryClassificationEvaluator to measure performance\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol = \"class\", rawPredictionCol = \"prediction\", metricName = \"areaUnderROC\")\n",
    "\n",
    "    best_params, best_metric = None, float(\"-inf\")\n",
    "\n",
    "    # Iterate over each parameter combination in the grid\n",
    "    for params in tqdm(paramGrid, desc=\"Hyperparameter Tuning\", leave = True):\n",
    "        fold_metrics = []\n",
    "\n",
    "        # Print parameter combination being evaluated\n",
    "        param_items = [f\"{param.name}: {value}\" for param, value in params.items()]\n",
    "\n",
    "        # For each fold, evaluate the parameter combination\n",
    "        for _, (train_df, test_df) in enumerate(folds):\n",
    "\n",
    "            # Vectorize features\n",
    "            train_df = vectorize_features(train_df, verbose = False, standard_scaler = standard_scaler)\n",
    "            test_df = vectorize_features(test_df, verbose = False, standard_scaler = standard_scaler)\n",
    "            check_patient_overlap(train_df, test_df, verbose_just_error = True)\n",
    "\n",
    "            # Train the model with the current parameters\n",
    "            current_model = model.copy(params).fit(train_df)\n",
    "\n",
    "            # Evaluate the model on the test data using the specified metric\n",
    "            predictions = current_model.transform(test_df)\n",
    "            metric = evaluator.evaluate(predictions)\n",
    "            fold_metrics.append(metric)\n",
    "        \n",
    "        # Calculate average metric across all folds for the current parameter combination\n",
    "        avg_metric = __builtins__.sum(fold_metrics) / len(fold_metrics)\n",
    "\n",
    "        print(f\"Average {evaluator.getMetricName()}: {avg_metric:.4f} | Evaluating Parameters:\", ', '.join(param_items))\n",
    "\n",
    "        # Update the best parameters if the current average metric is better\n",
    "        if avg_metric > best_metric:\n",
    "            best_metric = avg_metric\n",
    "            best_params = params\n",
    "\n",
    "    # Print the best parameters after evaluating all combinations\n",
    "    param_items = [f\"{param.name}: {value}\" for param, value in best_params.items()]\n",
    "    print(\"Best Overall Parameters:\", ', '.join(param_items))\n",
    "    print(f\"Best {evaluator.getMetricName()}: {best_metric:.4f}\")\n",
    "\n",
    "    return best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_best_model(model, best_params: list[dict], train_df: DataFrame, test_df: DataFrame, is_tree: bool = False, standard_scaler: bool = False):\n",
    "    \"\"\"Train the model on the full training data using the best parameters and evaluate on the test data.\"\"\"\n",
    "\n",
    "    # Vectorize features\n",
    "    train_df = vectorize_features(train_df, verbose = False, standard_scaler = standard_scaler)\n",
    "    test_df = vectorize_features(test_df, standard_scaler=standard_scaler)\n",
    "\n",
    "    # Train the model using the best parameters\n",
    "    best_model = model.copy(best_params).fit(train_df)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"class\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "    predictions = best_model.transform(test_df)\n",
    "    metric = evaluator.evaluate(predictions)\n",
    "\n",
    "    # Calculate additional metrics: accuracy, precision, recall\n",
    "    accuracy, precision, recall = calculate_metrics(predictions)\n",
    "\n",
    "    print(f\"Final Model Evaluation on Test Data {evaluator.getMetricName()}: {metric:.4f}\")\n",
    "    print(f\"Final Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "    # Print feature importances if the model is a tree-based model\n",
    "    if is_tree:\n",
    "        # Extract the feature importances from the model\n",
    "        feature_importances = best_model.featureImportances.toArray()\n",
    "\n",
    "        # Get feature column names from the assembler\n",
    "        feature_columns = train_df.schema['features'].metadata['ml_attr']['attrs']['numeric']\n",
    "        feature_names = [attr['name'] for attr in feature_columns]\n",
    "\n",
    "        # Combine feature names and their importances, then sort by importance\n",
    "        sorted_features = sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Print sorted feature importances\n",
    "        print(\"\\nSorted Feature Importances:\")\n",
    "        for name, importance in sorted_features:\n",
    "            print(f\"Feature: {name}, Importance: {importance:.4f}\")\n",
    "\n",
    "    # Show the first 5 names of wrongly classified rows\n",
    "    misclassified = predictions.filter(col('prediction') != col('class'))\n",
    "    names = misclassified.select('name').limit(5).rdd.flatMap(lambda x: x).collect()\n",
    "    print(\"\\nFirst 5 names of wrongly classified rows:\")\n",
    "    print(names)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model: str, file_name: str, paramGrid: list[dict], is_tree: bool = False, use_standard_scaler: bool = False):\n",
    "\n",
    "    # Load and preprocess the dataset\n",
    "    file_path = os.path.join(os.getcwd(), TARGET_DIR_NAME, file_name)\n",
    "    data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "    print(f\"\\n{'=' * 75}\\n Setting up\\n{'=' * 75}\\n\")\n",
    "    clean_data = preprocess_data(data)\n",
    "    #clean_data = clean_data.limit(100)\n",
    "\n",
    "    # split the data into train and test sets\n",
    "    train_df, test_df = train_test_split_by_patient(clean_data, test_ratio=0.2)\n",
    "\n",
    "    # Evaluate the model using patient-wise cross-validation to find the best parameters\n",
    "    print(f\"\\n{'=' * 75}\\n Hyperparameter tunning\\n{'=' * 75}\\n\")\n",
    "    best_params = determine_best_parameters_on_folds(model, train_df, paramGrid, num_folds=5, patient_column='patient', standard_scaler=use_standard_scaler)\n",
    "\n",
    "    # Train the best model on the full training data and evaluate on the test data\n",
    "    print(f\"\\n{'=' * 75}\\n Testing model on test dataset\\n{'=' * 75}\\n\")\n",
    "    best_model = train_and_evaluate_best_model(model, best_params, train_df, test_df, is_tree, standard_scaler=use_standard_scaler)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 512 - with lesion mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_512_lesion_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2174 (79.52%), Test size: 560 rows (20.48%)\n",
      "Class distribution in train_df: [0: 1087 (50.00%), 1: 1087 (50.00%)] | test_df: [0: 280 (50.00%), 1: 280 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 420 rows (19.32%) | Fold 2: 468 rows (21.53%) | Fold 3: 470 rows (21.62%) | Fold 4: 398 rows (18.31%) | Fold 5: 418 rows (19.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [02:44<00:00, 20.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Parameters: maxDepth: 5, maxBins: 32\n",
      "Best areaUnderROC: 0.9809\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 57\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9518\n",
      "Final Accuracy: 0.9518, Precision: 0.9288, Recall: 0.9786\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.9183\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0305\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0258\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0166\n",
      "Feature: original_firstorder_Median, Importance: 0.0044\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0043\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0000\n",
      "Feature: original_firstorder_Energy, Importance: 0.0000\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0000\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0000\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_firstorder_Variance, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000070_001-000070_MG_BL_Series-3_Image-1-1.png', 'hcs_003-000273_003-000273_MG_BL_Series-3_Image-1-1.png', 'hcs_003-000295_003-000295_MG_BL_Series-1008_Image-1-1.png', 'hcs_003-001034_003-001034_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1001-0.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2174 (79.52%), Test size: 560 rows (20.48%)\n",
      "Class distribution in train_df: [0: 1087 (50.00%), 1: 1087 (50.00%)] | test_df: [0: 280 (50.00%), 1: 280 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 420 rows (19.32%) | Fold 2: 468 rows (21.53%) | Fold 3: 470 rows (21.62%) | Fold 4: 398 rows (18.31%) | Fold 5: 418 rows (19.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 72/72 [37:45<00:00, 31.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.9870\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 57\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9536\n",
      "Final Accuracy: 0.9536, Precision: 0.9150, Recall: 1.0000\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.2748\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.1469\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0969\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0714\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0655\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0305\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0263\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0262\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0235\n",
      "Feature: original_firstorder_Mean, Importance: 0.0233\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0231\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0195\n",
      "Feature: original_firstorder_Range, Importance: 0.0164\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0159\n",
      "Feature: original_firstorder_Energy, Importance: 0.0143\n",
      "Feature: original_firstorder_Median, Importance: 0.0116\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0095\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0088\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0081\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0078\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0064\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0063\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0061\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0059\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0054\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0043\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0033\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0032\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0031\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0029\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0025\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0024\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0021\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0019\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0019\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0018\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0017\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0017\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0016\n",
      "Feature: original_firstorder_Variance, Importance: 0.0015\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0015\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0013\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0013\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0013\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0013\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0012\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0012\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0010\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0009\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0009\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0009\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0005\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0004\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1003-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-1_Image-1-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-2_Image-1-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-3_Image-1-0.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150, 200]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2174 (79.52%), Test size: 560 rows (20.48%)\n",
      "Class distribution in train_df: [0: 1087 (50.00%), 1: 1087 (50.00%)] | test_df: [0: 280 (50.00%), 1: 280 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 420 rows (19.32%) | Fold 2: 468 rows (21.53%) | Fold 3: 470 rows (21.62%) | Fold 4: 398 rows (18.31%) | Fold 5: 418 rows (19.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [06:51<00:00, 34.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n",
      "Best areaUnderROC: 0.9840\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 57\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9500\n",
      "Final Accuracy: 0.9500, Precision: 0.9091, Recall: 1.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-000265_003-000265_MG_BL_Series-4_Image-1-0.png', 'hcs_003-001369_003-001369_MG_BL_Series-1001_Image-1003-0.png', 'hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1003-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-1_Image-1-0.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4,  1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2174 (79.52%), Test size: 560 rows (20.48%)\n",
      "Class distribution in train_df: [0: 1087 (50.00%), 1: 1087 (50.00%)] | test_df: [0: 280 (50.00%), 1: 280 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 420 rows (19.32%) | Fold 2: 468 rows (21.53%) | Fold 3: 470 rows (21.62%) | Fold 4: 398 rows (18.31%) | Fold 5: 418 rows (19.23%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/15 [00:00<?, ?it/s]2024-09-16 02:00:53,139 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:01:00,888 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:01:08,170 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:01:12,987 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:01:18,756 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:01:24,208 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:01:32,143 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:01:37,826 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:01:45,524 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:01:51,496 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:   7%|▋         | 1/15 [01:05<15:23, 65.97s/it]2024-09-16 02:01:59,324 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:02:05,342 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:02:12,993 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:02:18,549 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:02:24,414 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:02:30,108 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:02:37,794 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:02:43,534 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:02:50,957 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:02:56,655 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  13%|█▎        | 2/15 [02:11<14:10, 65.42s/it]2024-09-16 02:03:04,575 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:03:11,197 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:03:18,703 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:03:24,679 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:03:32,182 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:03:37,965 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:03:45,149 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:03:50,451 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:03:57,923 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:04:03,745 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  20%|██        | 3/15 [03:18<13:14, 66.17s/it]2024-09-16 02:04:11,249 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:04:16,910 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:04:24,404 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:04:30,049 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:04:37,484 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:04:43,168 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:04:50,617 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:04:56,322 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:05:03,733 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:05:09,396 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  27%|██▋       | 4/15 [04:23<12:05, 65.96s/it]2024-09-16 02:05:16,817 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:05:22,729 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:05:30,219 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:05:35,973 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:05:43,464 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:05:49,782 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:05:57,231 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:06:03,057 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:06:10,531 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:06:16,350 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  33%|███▎      | 5/15 [05:30<11:03, 66.31s/it]2024-09-16 02:06:23,781 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:06:29,704 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:06:37,188 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:06:43,070 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:06:50,691 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:06:56,593 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:07:04,083 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:07:10,039 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:07:17,532 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:07:23,439 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  40%|████      | 6/15 [06:37<09:59, 66.58s/it]2024-09-16 02:07:30,934 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:07:36,651 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:07:44,249 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:07:49,941 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:07:57,484 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:08:03,199 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:08:10,859 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:08:16,585 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:08:24,010 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:08:29,690 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  47%|████▋     | 7/15 [07:43<08:51, 66.46s/it]2024-09-16 02:08:37,136 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:08:42,962 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:08:50,401 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:08:56,183 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:09:03,649 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:09:09,418 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:09:16,895 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:09:22,704 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:09:30,173 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:09:35,989 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  53%|█████▎    | 8/15 [08:50<07:44, 66.42s/it]2024-09-16 02:09:43,519 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:09:49,562 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:09:57,264 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:10:03,201 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:10:10,677 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:10:16,513 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:10:24,064 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:10:29,980 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:10:37,505 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:10:43,412 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  60%|██████    | 9/15 [09:57<06:40, 66.74s/it]2024-09-16 02:10:50,925 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:10:56,661 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:11:04,131 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:11:09,829 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:11:17,306 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:11:22,976 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:11:30,466 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:11:36,217 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:11:44,192 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:11:49,944 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  67%|██████▋   | 10/15 [11:04<05:33, 66.71s/it]2024-09-16 02:11:57,545 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:12:03,410 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:12:10,906 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:12:16,747 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:12:24,215 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:12:29,926 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:12:37,395 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:12:43,182 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:12:50,666 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:12:56,489 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  73%|███████▎  | 11/15 [12:10<04:26, 66.63s/it]2024-09-16 02:13:04,016 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:13:09,999 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:13:17,502 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:13:23,442 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:13:30,922 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:13:36,751 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:13:44,208 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:13:50,087 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:13:57,597 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:14:03,519 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  80%|████████  | 12/15 [13:17<03:20, 66.74s/it]2024-09-16 02:14:10,963 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:14:16,709 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:14:24,212 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:14:29,940 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:14:37,381 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:14:43,082 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:14:50,521 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:14:56,279 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:15:03,783 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:15:09,485 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  87%|████████▋ | 13/15 [14:23<02:13, 66.51s/it]2024-09-16 02:15:16,977 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:15:22,820 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:15:30,428 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:15:36,269 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:15:43,969 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:15:49,764 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:15:57,280 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:16:03,258 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:16:10,736 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:16:16,506 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  93%|█████████▎| 14/15 [15:30<01:06, 66.66s/it]2024-09-16 02:16:23,996 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:16:29,985 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:16:37,523 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:16:43,602 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:16:51,432 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:16:57,348 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:17:05,000 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:17:11,000 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-16 02:17:18,541 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 15, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:17:24,430 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 15/15 [16:38<00:00, 66.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Parameters: max_depth: 6, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.9901\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-16 02:17:29,923 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-16 02:17:35,813 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9571\n",
      "Final Accuracy: 0.9571, Precision: 0.9211, Recall: 1.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-001862_003-001862_MG_BL_Series-1001_Image-1003-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-1_Image-1-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-3_Image-1-0.png', 'hcs_003-001987_003-001987_MG_BL_Series-4_Image-1-0.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [3, 6, 9, 12, 15]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50, 100, 200]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 512 - with full mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_512_full_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2162 (79.08%), Test size: 572 rows (20.92%)\n",
      "Class distribution in train_df: [0: 1081 (50.00%), 1: 1081 (50.00%)] | test_df: [0: 286 (50.00%), 1: 286 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 424 rows (19.61%) | Fold 2: 422 rows (19.52%) | Fold 3: 450 rows (20.81%) | Fold 4: 398 rows (18.41%) | Fold 5: 468 rows (21.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [03:02<00:00, 22.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Overall Parameters: maxDepth: 5, maxBins: 32\n",
      "Best areaUnderROC: 0.6755\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 98\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.6731\n",
      "Final Accuracy: 0.6731, Precision: 0.6813, Recall: 0.6503\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_Variance, Importance: 0.5438\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0845\n",
      "Feature: original_glcm_Imc2, Importance: 0.0819\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0680\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0508\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0288\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0242\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0232\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0216\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0172\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0120\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0107\n",
      "Feature: original_glcm_Imc1, Importance: 0.0105\n",
      "Feature: original_firstorder_Energy, Importance: 0.0099\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0070\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0058\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Median, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0000\n",
      "Feature: original_glcm_Contrast, Importance: 0.0000\n",
      "Feature: original_glcm_Correlation, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0000\n",
      "Feature: original_glcm_Id, Importance: 0.0000\n",
      "Feature: original_glcm_Idm, Importance: 0.0000\n",
      "Feature: original_glcm_Idmn, Importance: 0.0000\n",
      "Feature: original_glcm_Idn, Importance: 0.0000\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0000\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0000\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0000\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_MCC, Importance: 0.0000\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0000\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0000\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0000\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000061_001-000061_MG_BL_Series-8_Image-1-0.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2162 (79.08%), Test size: 572 rows (20.92%)\n",
      "Class distribution in train_df: [0: 1081 (50.00%), 1: 1081 (50.00%)] | test_df: [0: 286 (50.00%), 1: 286 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 424 rows (19.61%) | Fold 2: 422 rows (19.52%) | Fold 3: 450 rows (20.81%) | Fold 4: 398 rows (18.41%) | Fold 5: 468 rows (21.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   3%|▎         | 1/36 [00:29<17:28, 29.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6850 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   6%|▌         | 2/36 [00:48<13:16, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6850 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 3/36 [01:09<12:14, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6774 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  11%|█         | 4/36 [01:31<11:41, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6774 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  14%|█▍        | 5/36 [01:50<10:48, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6791 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 6/36 [02:09<10:15, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6791 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|█▉        | 7/36 [02:36<10:53, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6793 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  22%|██▏       | 8/36 [03:02<11:01, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6793 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 9/36 [03:31<11:25, 25.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6874 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  28%|██▊       | 10/36 [04:01<11:38, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6874 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  31%|███       | 11/36 [04:38<12:27, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6754 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 12/36 [05:13<12:30, 31.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6754 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  36%|███▌      | 13/36 [05:52<12:52, 33.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6713 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  39%|███▉      | 14/36 [06:32<13:04, 35.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6713 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 15/36 [07:19<13:38, 38.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6716 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  44%|████▍     | 16/36 [08:05<13:41, 41.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6716 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  47%|████▋     | 17/36 [09:01<14:26, 45.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6693 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 18/36 [09:57<14:36, 48.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6693 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  53%|█████▎    | 19/36 [10:22<11:50, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6743 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  56%|█████▌    | 20/36 [10:48<09:50, 36.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6743 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 21/36 [11:12<08:16, 33.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6703 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  61%|██████    | 22/36 [11:40<07:21, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6703 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  64%|██████▍   | 23/36 [12:12<06:53, 31.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6723 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 24/36 [12:48<06:33, 32.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6723 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  69%|██████▉   | 25/36 [13:40<07:04, 38.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6776 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  72%|███████▏  | 26/36 [14:33<07:08, 42.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6776 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 27/36 [15:39<07:28, 49.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6819 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  78%|███████▊  | 28/36 [16:41<07:08, 53.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6819 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  81%|████████  | 29/36 [18:15<07:39, 65.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6803 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 30/36 [19:42<07:13, 72.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6803 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  86%|████████▌ | 31/36 [21:10<06:24, 76.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6680 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  89%|████████▉ | 32/36 [22:41<05:24, 81.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6680 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 33/36 [24:26<04:24, 88.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6762 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  94%|█████████▍| 34/36 [26:16<03:09, 94.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6762 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  97%|█████████▋| 35/36 [28:22<01:44, 104.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6711 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 36/36 [30:30<00:00, 50.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6711 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n",
      "Best Overall Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.6874\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.6818\n",
      "Final Accuracy: 0.6818, Precision: 0.6745, Recall: 0.7028\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_Variance, Importance: 0.0573\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0479\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0404\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0395\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0368\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0344\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0332\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0264\n",
      "Feature: original_firstorder_Energy, Importance: 0.0200\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0177\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0163\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0159\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0152\n",
      "Feature: original_glcm_MCC, Importance: 0.0143\n",
      "Feature: original_firstorder_Mean, Importance: 0.0137\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0136\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0134\n",
      "Feature: original_glcm_Imc1, Importance: 0.0134\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0133\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0133\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0131\n",
      "Feature: original_firstorder_Median, Importance: 0.0129\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0126\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0122\n",
      "Feature: original_glcm_Correlation, Importance: 0.0122\n",
      "Feature: original_glcm_Imc2, Importance: 0.0118\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0116\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0115\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0115\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0113\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0112\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0110\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0107\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0106\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0104\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0103\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0094\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0089\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0079\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0076\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0075\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0075\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0075\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0074\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0071\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0070\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0070\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0069\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0069\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0069\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0068\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0068\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0068\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0067\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0067\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0067\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0065\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0064\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0063\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0063\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0062\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0062\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0061\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0060\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0059\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0059\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0059\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0056\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0054\n",
      "Feature: original_glcm_Idmn, Importance: 0.0054\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0054\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0052\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0052\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0051\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0051\n",
      "Feature: original_glcm_Id, Importance: 0.0049\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0048\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0046\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0045\n",
      "Feature: original_glcm_Idm, Importance: 0.0045\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0045\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0044\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0044\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0042\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0040\n",
      "Feature: original_glcm_Idn, Importance: 0.0038\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0035\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0030\n",
      "Feature: original_glcm_Contrast, Importance: 0.0025\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0025\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0020\n",
      "Feature: original_firstorder_Range, Importance: 0.0005\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0002\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1004_Image-1004-0.png', 'hcs_003-000042_003-000042_MG_BL_Series-1001_Image-1001-1.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2162 (79.08%), Test size: 572 rows (20.92%)\n",
      "Class distribution in train_df: [0: 1081 (50.00%), 1: 1081 (50.00%)] | test_df: [0: 286 (50.00%), 1: 286 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 424 rows (19.61%) | Fold 2: 422 rows (19.52%) | Fold 3: 450 rows (20.81%) | Fold 4: 398 rows (18.41%) | Fold 5: 468 rows (21.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:38<07:03, 38.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7002 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [01:07<05:29, 32.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6918 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [01:32<04:23, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6895 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [01:54<03:32, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6900 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [02:49<04:17, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7028 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 6/12 [03:14<03:15, 32.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6918 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [03:39<02:30, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6895 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [04:01<01:50, 27.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6900 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [05:03<01:54, 38.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7028 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [05:28<01:08, 34.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6918 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [05:58<00:32, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6895 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [06:17<00:00, 31.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6900 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.01\n",
      "Best Overall Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n",
      "Best areaUnderROC: 0.7028\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial columns: 119, number of feature columns: 99\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.6993\n",
      "Final Accuracy: 0.6993, Precision: 0.6875, Recall: 0.7308\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000061_001-000061_MG_BL_Series-8_Image-1-0.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4, 1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2162 (79.08%), Test size: 572 rows (20.92%)\n",
      "Class distribution in train_df: [0: 1081 (50.00%), 1: 1081 (50.00%)] | test_df: [0: 286 (50.00%), 1: 286 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 424 rows (19.61%) | Fold 2: 422 rows (19.52%) | Fold 3: 450 rows (20.81%) | Fold 4: 398 rows (18.41%) | Fold 5: 468 rows (21.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/12 [00:00<?, ?it/s]2024-09-19 20:28:09,043 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:28:15,427 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:28:21,055 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:28:25,795 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:28:31,201 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:28:36,009 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:28:41,388 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:28:46,284 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:28:52,753 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:28:58,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:55<10:12, 55.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7087 | Evaluating Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:29:05,077 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:29:10,583 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:29:17,609 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:29:23,201 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:29:30,125 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:29:35,153 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:29:40,611 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:29:45,579 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:29:52,536 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:29:58,139 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [01:55<09:42, 58.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7042 | Evaluating Parameters: max_depth: 3, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:30:05,250 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:30:11,138 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:30:18,048 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:30:23,905 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:30:30,879 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:30:36,321 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:30:41,704 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:30:46,952 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:30:52,303 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:30:58,036 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [02:55<08:50, 58.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6984 | Evaluating Parameters: max_depth: 3, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:31:05,085 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:31:11,037 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:31:17,950 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:31:23,933 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:31:30,817 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:31:36,752 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:31:43,635 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:31:49,499 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:31:56,318 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:32:02,236 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [03:58<08:04, 60.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6816 | Evaluating Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:32:07,527 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:32:13,247 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:32:19,092 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:32:25,672 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:32:32,571 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:32:39,038 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:32:45,886 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:32:52,246 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:32:59,174 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:33:05,650 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [05:03<07:14, 62.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6775 | Evaluating Parameters: max_depth: 6, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:33:12,575 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:33:20,073 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:33:27,172 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:33:34,623 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:33:40,098 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:33:46,648 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:33:53,301 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:34:01,196 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:34:08,396 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:34:15,815 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  50%|█████     | 6/12 [06:13<06:28, 64.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6800 | Evaluating Parameters: max_depth: 6, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:34:22,934 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:34:29,671 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:34:36,557 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:34:43,288 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:34:50,308 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:34:56,946 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:35:03,821 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:35:09,908 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:35:16,608 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:35:23,309 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [07:20<05:28, 65.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6775 | Evaluating Parameters: max_depth: 9, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:35:30,287 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:35:37,984 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:35:43,552 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:35:50,402 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:35:57,310 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:36:04,913 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:36:11,830 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:36:19,420 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:36:26,372 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:36:34,121 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [08:31<04:29, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6707 | Evaluating Parameters: max_depth: 9, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:36:41,073 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:36:50,418 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:36:56,281 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:37:04,516 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:37:11,622 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:37:20,659 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:37:27,720 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:37:36,806 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:37:44,149 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:37:53,439 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [09:51<03:33, 71.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6738 | Evaluating Parameters: max_depth: 9, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:38:01,200 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:38:07,890 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:38:14,425 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:38:22,071 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:38:28,989 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:38:36,940 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:38:44,024 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:38:51,500 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:38:57,123 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:39:03,673 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [11:01<02:21, 70.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6783 | Evaluating Parameters: max_depth: 12, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:39:10,686 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:39:19,333 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:39:26,418 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:39:35,150 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:39:42,126 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:39:50,886 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:39:56,904 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:40:05,185 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:40:12,139 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:40:20,724 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [12:18<01:12, 72.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6724 | Evaluating Parameters: max_depth: 12, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 20:40:27,746 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:40:37,185 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:40:42,637 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:40:51,998 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:40:59,073 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:41:09,230 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:41:16,229 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:41:26,350 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 20:41:33,326 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:41:43,276 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 12/12 [13:40<00:00, 68.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6807 | Evaluating Parameters: max_depth: 12, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best Overall Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.7087\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-19 20:41:48,241 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 20:41:53,907 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7133\n",
      "Final Accuracy: 0.7133, Precision: 0.6993, Recall: 0.7483\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000061_001-000061_MG_BL_Series-8_Image-1-0.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [3, 6, 9, 12]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50, 100, 200]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2162 (79.08%), Test size: 572 rows (20.92%)\n",
      "Class distribution in train_df: [0: 1081 (50.00%), 1: 1081 (50.00%)] | test_df: [0: 286 (50.00%), 1: 286 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 424 rows (19.61%) | Fold 2: 422 rows (19.52%) | Fold 3: 450 rows (20.81%) | Fold 4: 398 rows (18.41%) | Fold 5: 468 rows (21.65%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:17<02:00, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6755 | Evaluating Parameters: maxDepth: 5, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [00:35<01:46, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6621 | Evaluating Parameters: maxDepth: 5, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [00:53<01:29, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6439 | Evaluating Parameters: maxDepth: 10, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 4/8 [01:11<01:11, 17.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6287 | Evaluating Parameters: maxDepth: 10, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [01:32<00:56, 18.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6247 | Evaluating Parameters: maxDepth: 15, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [01:50<00:37, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6065 | Evaluating Parameters: maxDepth: 15, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [02:12<00:19, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6243 | Evaluating Parameters: maxDepth: 20, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [02:31<00:00, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6045 | Evaluating Parameters: maxDepth: 20, maxBins: 64\n",
      "Best Overall Parameters: maxDepth: 5, maxBins: 32\n",
      "Best areaUnderROC: 0.6755\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.6731\n",
      "Final Accuracy: 0.6731, Precision: 0.6813, Recall: 0.6503\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_Variance, Importance: 0.5438\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0845\n",
      "Feature: original_glcm_Imc2, Importance: 0.0819\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0680\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0508\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0288\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0242\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0232\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0216\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0172\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0120\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0107\n",
      "Feature: original_glcm_Imc1, Importance: 0.0105\n",
      "Feature: original_firstorder_Energy, Importance: 0.0099\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0070\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0058\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Median, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0000\n",
      "Feature: original_glcm_Contrast, Importance: 0.0000\n",
      "Feature: original_glcm_Correlation, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0000\n",
      "Feature: original_glcm_Id, Importance: 0.0000\n",
      "Feature: original_glcm_Idm, Importance: 0.0000\n",
      "Feature: original_glcm_Idmn, Importance: 0.0000\n",
      "Feature: original_glcm_Idn, Importance: 0.0000\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0000\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0000\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0000\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_MCC, Importance: 0.0000\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0000\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0000\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0000\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000061_001-000061_MG_BL_Series-8_Image-1-0.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 256 - with lesion mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_256_lesion_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2255 (80.74%), Test size: 538 rows (19.26%)\n",
      "Class distribution in train_df: [0: 1127 (49.98%), 1: 1128 (50.02%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 510 rows (22.62%) | Fold 2: 414 rows (18.36%) | Fold 3: 417 rows (18.49%) | Fold 4: 474 rows (21.02%) | Fold 5: 440 rows (19.51%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:14<01:38, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9719 | Evaluating Parameters: maxDepth: 5, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [00:27<01:23, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9724 | Evaluating Parameters: maxDepth: 5, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [00:42<01:10, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9524 | Evaluating Parameters: maxDepth: 10, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 4/8 [00:56<00:56, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9515 | Evaluating Parameters: maxDepth: 10, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [01:11<00:43, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9474 | Evaluating Parameters: maxDepth: 15, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [01:26<00:29, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9482 | Evaluating Parameters: maxDepth: 15, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [01:41<00:14, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9479 | Evaluating Parameters: maxDepth: 20, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [01:56<00:00, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9482 | Evaluating Parameters: maxDepth: 20, maxBins: 64\n",
      "Best Overall Parameters: maxDepth: 5, maxBins: 64\n",
      "Best areaUnderROC: 0.9724\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9740\n",
      "Final Accuracy: 0.9740, Precision: 0.9636, Recall: 0.9851\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.9875\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0076\n",
      "Feature: original_firstorder_Median, Importance: 0.0020\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0015\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0013\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0000\n",
      "Feature: original_firstorder_Energy, Importance: 0.0000\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0000\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0000\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_firstorder_Variance, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000245_003-000245_MG_BL_Series-1008_Image-1-1.png', 'hcs_003-000259_003-000259_MG_BL_Series-2_Image-1-1.png', 'hcs_003-001204_003-001204_MG_BL_Series-1001_Image-1002-0.png', 'hcs_003-001223_003-001223_MG_BL_Series-1694_Image-1694-1.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2255 (80.74%), Test size: 538 rows (19.26%)\n",
      "Class distribution in train_df: [0: 1127 (49.98%), 1: 1128 (50.02%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 510 rows (22.62%) | Fold 2: 414 rows (18.36%) | Fold 3: 417 rows (18.49%) | Fold 4: 474 rows (21.02%) | Fold 5: 440 rows (19.51%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   3%|▎         | 1/36 [00:15<08:47, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9605 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   6%|▌         | 2/36 [00:30<08:30, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9605 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 3/36 [00:45<08:18, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9598 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  11%|█         | 4/36 [01:00<08:05, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9598 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  14%|█▍        | 5/36 [01:16<08:02, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9582 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 6/36 [01:32<07:52, 15.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9582 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|█▉        | 7/36 [01:51<07:59, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9659 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  22%|██▏       | 8/36 [02:09<08:00, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9659 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 9/36 [02:28<07:58, 17.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9633 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  28%|██▊       | 10/36 [02:47<07:50, 18.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9633 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  31%|███       | 11/36 [03:08<07:53, 18.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9642 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 12/36 [03:29<07:48, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9642 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  36%|███▌      | 13/36 [03:49<07:35, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9641 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  39%|███▉      | 14/36 [04:10<07:22, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9641 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 15/36 [04:32<07:12, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9633 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  44%|████▍     | 16/36 [04:53<06:58, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9633 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  47%|████▋     | 17/36 [05:18<06:56, 21.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9628 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 18/36 [05:43<06:51, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9628 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  53%|█████▎    | 19/36 [06:00<06:02, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9646 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  56%|█████▌    | 20/36 [06:18<05:23, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9646 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 21/36 [06:37<04:58, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9609 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  61%|██████    | 22/36 [06:56<04:36, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9609 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  64%|██████▍   | 23/36 [07:19<04:26, 20.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9613 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 24/36 [07:42<04:17, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9613 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  69%|██████▉   | 25/36 [08:11<04:19, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9666 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  72%|███████▏  | 26/36 [08:40<04:11, 25.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9666 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 27/36 [09:15<04:13, 28.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9658 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  78%|███████▊  | 28/36 [09:48<03:55, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9658 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  81%|████████  | 29/36 [10:31<03:54, 33.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9642 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 30/36 [11:13<03:37, 36.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9642 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  86%|████████▌ | 31/36 [11:51<03:03, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9648 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  89%|████████▉ | 32/36 [12:27<02:25, 36.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9648 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 33/36 [13:10<01:54, 38.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9653 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  94%|█████████▍| 34/36 [13:53<01:19, 39.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9653 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  97%|█████████▋| 35/36 [14:45<00:43, 43.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9639 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 36/36 [15:37<00:00, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9639 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n",
      "Best Overall Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.9666\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9740\n",
      "Final Accuracy: 0.9740, Precision: 0.9636, Recall: 0.9851\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.2132\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.1198\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0705\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0655\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0547\n",
      "Feature: original_firstorder_Mean, Importance: 0.0527\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0520\n",
      "Feature: original_firstorder_Median, Importance: 0.0510\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0362\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0218\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0217\n",
      "Feature: original_firstorder_Range, Importance: 0.0199\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0191\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0122\n",
      "Feature: original_firstorder_Energy, Importance: 0.0106\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0096\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0086\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0085\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0077\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0070\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0069\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0067\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0063\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0061\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0060\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0055\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0055\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0055\n",
      "Feature: original_firstorder_Variance, Importance: 0.0053\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0050\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0048\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0047\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0046\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0045\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0043\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0043\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0043\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0041\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0036\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0036\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0035\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0034\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0032\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0030\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0029\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0028\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0027\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0026\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0026\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0025\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0023\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0023\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0016\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0006\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0003\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000017_003-000017_MG_BL_Series-1004_Image-1004-1.png', 'hcs_003-000677_003-000677_MG_BL_Series-1001_Image-1004-1.png', 'hcs_003-000971_003-000971_MG_BL_Series-1004_Image-1004-1.png', 'hcs_003-001204_003-001204_MG_BL_Series-1001_Image-1002-0.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2255 (80.74%), Test size: 538 rows (19.26%)\n",
      "Class distribution in train_df: [0: 1127 (49.98%), 1: 1128 (50.02%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 510 rows (22.62%) | Fold 2: 414 rows (18.36%) | Fold 3: 417 rows (18.49%) | Fold 4: 474 rows (21.02%) | Fold 5: 440 rows (19.51%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:33<06:06, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9361 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [00:55<04:26, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9338 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [01:17<03:41, 24.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [01:35<02:57, 22.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [02:14<03:17, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9361 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 6/12 [02:33<02:29, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9338 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [02:57<02:02, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [03:15<01:30, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [03:54<01:22, 27.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9361 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [04:12<00:49, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9338 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [04:37<00:24, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [04:56<00:00, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9189 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.01\n",
      "Best Overall Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n",
      "Best areaUnderROC: 0.9361\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial columns: 119, number of feature columns: 58\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9610\n",
      "Final Accuracy: 0.9610, Precision: 0.9397, Recall: 0.9851\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-000017_003-000017_MG_BL_Series-1004_Image-1004-1.png', 'hcs_003-000035_003-000035_MG_BL_Series-1002_Image-1002-1.png', 'hcs_003-000307_003-000307_MG_BL_Series-4_Image-1-0.png', 'hcs_003-000971_003-000971_MG_BL_Series-1004_Image-1004-1.png', 'hcs_003-001334_003-001334_MG_TP0_1_Series-1001_Image-1004-1.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4,  1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2255 (80.74%), Test size: 538 rows (19.26%)\n",
      "Class distribution in train_df: [0: 1127 (49.98%), 1: 1128 (50.02%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 510 rows (22.62%) | Fold 2: 414 rows (18.36%) | Fold 3: 417 rows (18.49%) | Fold 4: 474 rows (21.02%) | Fold 5: 440 rows (19.51%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/12 [00:00<?, ?it/s]2024-09-19 21:23:10,285 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:23:15,004 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:23:20,252 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:23:24,926 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:23:30,176 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:23:34,883 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:23:40,377 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:23:45,038 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:23:50,392 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:23:55,159 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:50<09:13, 50.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9709 | Evaluating Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:24:01,234 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:24:06,768 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:24:13,691 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:24:19,357 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:24:26,373 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:24:31,687 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:24:36,908 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:24:45,160 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:24:57,064 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:25:05,258 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [02:04<10:41, 64.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9692 | Evaluating Parameters: max_depth: 3, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:25:17,075 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:25:23,144 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:25:28,258 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:25:33,082 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:25:38,278 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:25:43,101 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:25:48,355 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:25:53,224 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:25:58,442 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:03,319 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [02:58<08:56, 59.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9684 | Evaluating Parameters: max_depth: 3, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:26:08,628 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:13,383 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:26:18,666 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:23,479 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:26:28,738 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:33,578 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:26:38,867 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:43,707 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:26:49,016 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:26:53,796 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [03:48<07:27, 55.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9693 | Evaluating Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:26:59,128 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:27:04,735 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:27:11,763 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:27:17,356 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:27:24,228 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:27:29,806 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:27:36,112 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:27:40,953 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:27:46,244 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:27:51,252 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [04:46<06:35, 56.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9706 | Evaluating Parameters: max_depth: 6, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:27:56,643 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:01,761 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:28:08,539 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:14,327 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:28:21,287 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:27,064 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:28:33,944 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:39,033 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:28:44,325 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:49,512 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  50%|█████     | 6/12 [05:44<05:42, 57.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9698 | Evaluating Parameters: max_depth: 6, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:28:54,883 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:28:59,774 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:29:06,755 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:29:12,353 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:29:19,218 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:29:24,889 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:29:31,951 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:29:37,476 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:29:43,242 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:29:48,124 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [06:43<04:48, 57.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9683 | Evaluating Parameters: max_depth: 9, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:29:53,467 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:29:58,610 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:30:04,588 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:30:10,295 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:30:17,187 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:30:23,027 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:30:29,932 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:30:35,608 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:30:42,548 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:30:48,347 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [07:44<03:54, 58.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9693 | Evaluating Parameters: max_depth: 9, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:30:54,652 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:30:59,860 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:31:05,215 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:31:10,460 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:31:17,215 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:31:23,135 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:31:30,077 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:31:35,899 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:31:42,836 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:31:48,695 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [08:44<02:57, 59.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9693 | Evaluating Parameters: max_depth: 9, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:31:55,639 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:32:01,199 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:32:08,107 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:32:13,660 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:32:18,997 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:32:23,996 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:32:29,654 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:32:35,273 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:32:42,173 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:32:47,796 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [09:43<01:58, 59.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9701 | Evaluating Parameters: max_depth: 12, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:32:54,760 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:33:00,564 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:33:07,495 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:33:13,356 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:33:20,425 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:33:26,257 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:33:33,119 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:33:38,861 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:33:45,747 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:33:51,501 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [10:46<01:00, 60.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9703 | Evaluating Parameters: max_depth: 12, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 21:33:56,998 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:34:02,727 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:34:09,648 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:34:15,590 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:34:22,636 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:34:28,693 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:34:35,637 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:34:41,504 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 21:34:48,398 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:34:54,297 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 12/12 [11:50<00:00, 59.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9707 | Evaluating Parameters: max_depth: 12, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best Overall Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.9709\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-19 21:34:59,246 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 21:35:04,998 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9740\n",
      "Final Accuracy: 0.9740, Precision: 0.9570, Recall: 0.9926\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000245_003-000245_MG_BL_Series-1008_Image-1-1.png', 'hcs_003-000286_003-000286_MG_BL_Series-1010_Image-1-0.png', 'hcs_003-000971_003-000971_MG_BL_Series-1004_Image-1004-1.png', 'hcs_003-001204_003-001204_MG_BL_Series-1001_Image-1002-0.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [3, 6, 9, 12]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50, 100, 200]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 256 - with full mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_256_full_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2286 (81.82%), Test size: 508 rows (18.18%)\n",
      "Class distribution in train_df: [0: 1143 (50.00%), 1: 1143 (50.00%)] | test_df: [0: 254 (50.00%), 1: 254 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 494 rows (21.61%) | Fold 2: 398 rows (17.41%) | Fold 3: 448 rows (19.60%) | Fold 4: 480 rows (21.00%) | Fold 5: 466 rows (20.38%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:17<02:05, 17.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7169 | Evaluating Parameters: maxDepth: 5, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [00:37<01:53, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7226 | Evaluating Parameters: maxDepth: 5, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [00:56<01:34, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6844 | Evaluating Parameters: maxDepth: 10, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 4/8 [01:17<01:18, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6656 | Evaluating Parameters: maxDepth: 10, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [01:39<01:01, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6628 | Evaluating Parameters: maxDepth: 15, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [01:59<00:40, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6569 | Evaluating Parameters: maxDepth: 15, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [02:23<00:21, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6582 | Evaluating Parameters: maxDepth: 20, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [02:43<00:00, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.6489 | Evaluating Parameters: maxDepth: 20, maxBins: 64\n",
      "Best Overall Parameters: maxDepth: 5, maxBins: 64\n",
      "Best areaUnderROC: 0.7226\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7244\n",
      "Final Accuracy: 0.7244, Precision: 0.7280, Recall: 0.7165\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.7217\n",
      "Feature: original_firstorder_Variance, Importance: 0.0899\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0313\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0222\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0189\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0148\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0148\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0127\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0123\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0111\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0109\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0101\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0098\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0064\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0060\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0039\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0033\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0000\n",
      "Feature: original_firstorder_Energy, Importance: 0.0000\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Median, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0000\n",
      "Feature: original_glcm_Contrast, Importance: 0.0000\n",
      "Feature: original_glcm_Correlation, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0000\n",
      "Feature: original_glcm_Id, Importance: 0.0000\n",
      "Feature: original_glcm_Idm, Importance: 0.0000\n",
      "Feature: original_glcm_Idmn, Importance: 0.0000\n",
      "Feature: original_glcm_Idn, Importance: 0.0000\n",
      "Feature: original_glcm_Imc1, Importance: 0.0000\n",
      "Feature: original_glcm_Imc2, Importance: 0.0000\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0000\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0000\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0000\n",
      "Feature: original_glcm_MCC, Importance: 0.0000\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0000\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0000\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0000\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000074_001-000074_MG_TP1_Series-4_Image-1-1.png', 'auth_001-000084_001-000084_MG_BL_Series-1_Image-1-1.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2286 (81.82%), Test size: 508 rows (18.18%)\n",
      "Class distribution in train_df: [0: 1143 (50.00%), 1: 1143 (50.00%)] | test_df: [0: 254 (50.00%), 1: 254 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 494 rows (21.61%) | Fold 2: 398 rows (17.41%) | Fold 3: 448 rows (19.60%) | Fold 4: 480 rows (21.00%) | Fold 5: 466 rows (20.38%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   3%|▎         | 1/36 [00:18<10:45, 18.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7319 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   6%|▌         | 2/36 [00:40<11:29, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7319 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 3/36 [01:01<11:20, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7309 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  11%|█         | 4/36 [01:21<10:53, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7309 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  14%|█▍        | 5/36 [01:45<11:15, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7353 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 6/36 [02:04<10:27, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7353 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|█▉        | 7/36 [02:34<11:36, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7334 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  22%|██▏       | 8/36 [03:07<12:26, 26.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7334 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 9/36 [03:43<13:19, 29.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7302 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  28%|██▊       | 10/36 [04:23<14:11, 32.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7302 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  31%|███       | 11/36 [05:10<15:28, 37.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7318 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 12/36 [05:58<16:09, 40.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7318 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  36%|███▌      | 13/36 [06:48<16:41, 43.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7259 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  39%|███▉      | 14/36 [07:35<16:19, 44.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7259 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 15/36 [08:35<17:11, 49.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7350 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  44%|████▍     | 16/36 [09:30<16:59, 50.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7350 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  47%|████▋     | 17/36 [10:45<18:24, 58.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7326 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 18/36 [11:59<18:50, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7326 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  53%|█████▎    | 19/36 [12:30<15:04, 53.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7323 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  56%|█████▌    | 20/36 [13:00<12:21, 46.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7323 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 21/36 [13:34<10:40, 42.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7340 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  61%|██████    | 22/36 [14:09<09:23, 40.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7340 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  64%|██████▍   | 23/36 [14:49<08:45, 40.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7300 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 24/36 [15:29<08:03, 40.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7300 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  69%|██████▉   | 25/36 [16:38<08:57, 48.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7345 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  72%|███████▏  | 26/36 [17:48<09:10, 55.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7345 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 27/36 [19:19<09:52, 65.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7368 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  78%|███████▊  | 28/36 [20:43<09:31, 71.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7368 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  81%|████████  | 29/36 [22:53<10:22, 89.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7347 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 30/36 [24:39<09:24, 94.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7347 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  86%|████████▌ | 31/36 [26:27<08:11, 98.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7292 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  89%|████████▉ | 32/36 [28:15<06:44, 101.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7292 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 33/36 [30:21<05:25, 108.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7402 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  94%|█████████▍| 34/36 [32:25<03:46, 113.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7402 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  97%|█████████▋| 35/36 [35:21<02:12, 132.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7409 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 36/36 [37:53<00:00, 63.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7409 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n",
      "Best Overall Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.7409\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7441\n",
      "Final Accuracy: 0.7441, Precision: 0.7562, Recall: 0.7205\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0611\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0532\n",
      "Feature: original_firstorder_Variance, Importance: 0.0469\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0406\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0349\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0347\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0273\n",
      "Feature: original_firstorder_Energy, Importance: 0.0255\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0255\n",
      "Feature: original_firstorder_Mean, Importance: 0.0225\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0214\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0213\n",
      "Feature: original_firstorder_Median, Importance: 0.0194\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0147\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0134\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0130\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0125\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0123\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0121\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0118\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0108\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0107\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0106\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0105\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0105\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0101\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0101\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0098\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0098\n",
      "Feature: original_glcm_MCC, Importance: 0.0095\n",
      "Feature: original_glcm_Correlation, Importance: 0.0094\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0093\n",
      "Feature: original_glcm_Imc1, Importance: 0.0092\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0089\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0089\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0088\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0086\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0084\n",
      "Feature: original_glcm_Imc2, Importance: 0.0083\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0079\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0078\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0077\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0077\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0076\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0075\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0073\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0072\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0072\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0072\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0072\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0071\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0071\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0068\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0065\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0064\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0064\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0063\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0063\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0062\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0062\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0060\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0058\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0057\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0055\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0055\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0054\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0054\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0054\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0053\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0052\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0052\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0052\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0051\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0051\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0051\n",
      "Feature: original_glcm_Id, Importance: 0.0050\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0048\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0047\n",
      "Feature: original_glcm_Idmn, Importance: 0.0045\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0043\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0043\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0042\n",
      "Feature: original_glcm_Idn, Importance: 0.0041\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0041\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0040\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0040\n",
      "Feature: original_glcm_Contrast, Importance: 0.0039\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0039\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0036\n",
      "Feature: original_glcm_Idm, Importance: 0.0034\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0019\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0005\n",
      "Feature: original_firstorder_Range, Importance: 0.0004\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0001\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000074_001-000074_MG_TP1_Series-4_Image-1-1.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000024_003-000024_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2286 (81.82%), Test size: 508 rows (18.18%)\n",
      "Class distribution in train_df: [0: 1143 (50.00%), 1: 1143 (50.00%)] | test_df: [0: 254 (50.00%), 1: 254 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 494 rows (21.61%) | Fold 2: 398 rows (17.41%) | Fold 3: 448 rows (19.60%) | Fold 4: 480 rows (21.00%) | Fold 5: 466 rows (20.38%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:39<07:19, 39.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7358 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [01:06<05:18, 31.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7392 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [01:35<04:38, 30.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7364 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [01:58<03:41, 27.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7360 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [02:59<04:38, 39.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7339 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 6/12 [03:21<03:20, 33.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7392 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [03:53<02:45, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7364 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [04:18<02:01, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7360 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [05:16<01:57, 39.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7339 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [05:41<01:09, 34.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7392 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [06:14<00:34, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7364 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [06:39<00:00, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7360 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.01\n",
      "Best Overall Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n",
      "Best areaUnderROC: 0.7392\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial columns: 119, number of feature columns: 99\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.7382\n",
      "Final Accuracy: 0.7382, Precision: 0.7249, Recall: 0.7677\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000061_001-000061_MG_BL_Series-8_Image-1-1.png', 'hcs_003-000024_003-000024_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4,  1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2286 (81.82%), Test size: 508 rows (18.18%)\n",
      "Class distribution in train_df: [0: 1143 (50.00%), 1: 1143 (50.00%)] | test_df: [0: 254 (50.00%), 1: 254 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 494 rows (21.61%) | Fold 2: 398 rows (17.41%) | Fold 3: 448 rows (19.60%) | Fold 4: 480 rows (21.00%) | Fold 5: 466 rows (20.38%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/12 [00:00<?, ?it/s]2024-09-19 22:25:06,036 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:25:22,296 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:25:27,596 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:25:32,490 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:25:37,797 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:25:42,751 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:25:48,092 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:25:53,057 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:25:58,626 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:26:04,479 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:   8%|▊         | 1/12 [01:04<11:53, 64.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7464 | Evaluating Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:26:11,513 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:26:17,552 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:26:24,481 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:26:30,458 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:26:37,441 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:26:43,490 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:26:50,666 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:26:56,491 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:27:03,766 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:27:09,408 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [02:09<10:48, 64.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7427 | Evaluating Parameters: max_depth: 3, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:27:16,429 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:27:22,078 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:27:28,310 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:27:34,262 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:27:41,249 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:27:47,165 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:27:54,249 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:28:00,246 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:28:07,505 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:28:13,468 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [03:14<09:41, 64.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7408 | Evaluating Parameters: max_depth: 3, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:28:20,787 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:28:26,808 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:28:33,948 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:28:39,955 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:28:46,683 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:28:52,643 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:28:59,840 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:29:05,819 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:29:12,927 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:29:18,908 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [04:21<08:44, 65.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7442 | Evaluating Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:29:29,183 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:29:36,554 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:29:44,245 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:29:50,922 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:29:58,145 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:30:04,974 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:30:12,372 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:30:19,165 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:30:26,477 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:30:33,179 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [05:33<07:57, 68.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7420 | Evaluating Parameters: max_depth: 6, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:30:40,661 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:30:48,624 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:30:56,074 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:31:03,973 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:31:11,346 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:31:19,114 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:31:26,646 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:31:34,408 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:31:41,812 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:31:49,520 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  50%|█████     | 6/12 [06:50<07:05, 70.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7382 | Evaluating Parameters: max_depth: 6, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:31:57,026 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:32:03,968 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:32:11,304 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:32:18,298 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:32:25,556 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:32:32,623 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:32:39,979 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:32:46,995 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:32:54,322 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:33:01,404 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [08:02<05:56, 71.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7502 | Evaluating Parameters: max_depth: 9, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:33:08,906 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:33:16,855 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:33:24,197 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:33:32,222 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:33:39,624 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:33:47,901 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:33:55,389 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:34:03,361 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:34:10,899 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:34:18,960 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [09:19<04:52, 73.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7547 | Evaluating Parameters: max_depth: 9, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:34:26,325 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:34:35,893 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:34:43,343 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:34:53,028 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:35:00,404 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:35:09,877 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:35:17,346 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:35:26,926 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:35:34,240 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:35:43,976 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [10:44<03:51, 77.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7537 | Evaluating Parameters: max_depth: 9, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:35:51,701 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:35:59,350 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:36:06,810 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:36:14,422 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:36:21,774 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:36:29,338 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:36:36,684 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:36:44,296 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:36:51,565 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:36:59,360 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [11:59<02:32, 76.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7515 | Evaluating Parameters: max_depth: 12, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:37:06,740 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:37:15,537 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:37:23,042 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:37:31,882 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:37:39,220 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:37:47,991 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:37:55,479 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:38:04,239 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:38:11,582 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:38:20,435 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [13:21<01:17, 77.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7453 | Evaluating Parameters: max_depth: 12, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 22:38:27,854 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:38:38,242 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:38:45,661 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:38:56,596 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:39:04,146 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:39:14,580 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:39:21,986 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:39:32,365 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-19 22:39:39,778 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 200}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:39:50,207 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 12/12 [14:50<00:00, 74.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7414 | Evaluating Parameters: max_depth: 12, n_estimators: 200, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best Overall Parameters: max_depth: 9, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.7547\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-19 22:39:55,469 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-19 22:40:03,828 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7579\n",
      "Final Accuracy: 0.7579, Precision: 0.7673, Recall: 0.7402\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000074_001-000074_MG_TP1_Series-4_Image-1-1.png', 'auth_001-000084_001-000084_MG_BL_Series-1_Image-1-0.png', 'auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000024_003-000024_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [3, 6, 9, 12]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50, 100, 200]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 128 - with lesion mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_128_lesion_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2261 (80.84%), Test size: 536 rows (19.16%)\n",
      "Class distribution in train_df: [0: 1130 (49.98%), 1: 1131 (50.02%)] | test_df: [0: 268 (50.00%), 1: 268 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 430 rows (19.02%) | Fold 2: 448 rows (19.81%) | Fold 3: 428 rows (18.93%) | Fold 4: 496 rows (21.94%) | Fold 5: 459 rows (20.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:18<02:09, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9066 | Evaluating Parameters: maxDepth: 5, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [00:39<02:01, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.9093 | Evaluating Parameters: maxDepth: 5, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [00:57<01:34, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8883 | Evaluating Parameters: maxDepth: 10, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 4/8 [01:19<01:20, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8926 | Evaluating Parameters: maxDepth: 10, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [01:36<00:57, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8712 | Evaluating Parameters: maxDepth: 15, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [01:59<00:40, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8719 | Evaluating Parameters: maxDepth: 15, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [02:17<00:19, 19.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8703 | Evaluating Parameters: maxDepth: 20, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [02:41<00:00, 20.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8706 | Evaluating Parameters: maxDepth: 20, maxBins: 64\n",
      "Best Overall Parameters: maxDepth: 5, maxBins: 64\n",
      "Best areaUnderROC: 0.9093\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9459\n",
      "Final Accuracy: 0.9459, Precision: 0.9314, Recall: 0.9627\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.7278\n",
      "Feature: original_firstorder_Energy, Importance: 0.2294\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0163\n",
      "Feature: original_glcm_Correlation, Importance: 0.0122\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0121\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0021\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0000\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0000\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0000\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Median, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_firstorder_Variance, Importance: 0.0000\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0000\n",
      "Feature: original_glcm_Contrast, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0000\n",
      "Feature: original_glcm_Id, Importance: 0.0000\n",
      "Feature: original_glcm_Idm, Importance: 0.0000\n",
      "Feature: original_glcm_Idmn, Importance: 0.0000\n",
      "Feature: original_glcm_Idn, Importance: 0.0000\n",
      "Feature: original_glcm_Imc1, Importance: 0.0000\n",
      "Feature: original_glcm_Imc2, Importance: 0.0000\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0000\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0000\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0000\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_MCC, Importance: 0.0000\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0000\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0000\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0000\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000074_001-000074_MG_TP1_Series-4_Image-1-1.png', 'hcs_003-000242_003-000242_MG_BL_Series-3_Image-1-1.png', 'hcs_003-000307_003-000307_MG_BL_Series-4_Image-1-0.png', 'hcs_003-000620_003-000620_MG_BL_Series-1695_Image-1695-1.png', 'hcs_003-000667_003-000667_MG_BL_Series-1001_Image-1001-0.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2261 (80.84%), Test size: 536 rows (19.16%)\n",
      "Class distribution in train_df: [0: 1130 (49.98%), 1: 1131 (50.02%)] | test_df: [0: 268 (50.00%), 1: 268 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 430 rows (19.02%) | Fold 2: 448 rows (19.81%) | Fold 3: 428 rows (18.93%) | Fold 4: 496 rows (21.94%) | Fold 5: 459 rows (20.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   3%|▎         | 1/36 [00:22<12:57, 22.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8810 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   6%|▌         | 2/36 [00:38<10:45, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8810 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 3/36 [01:00<11:12, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8822 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  11%|█         | 4/36 [01:18<10:10, 19.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8822 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  14%|█▍        | 5/36 [01:41<10:38, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8807 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 6/36 [01:59<09:53, 19.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8807 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|█▉        | 7/36 [02:25<10:34, 21.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8886 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  22%|██▏       | 8/36 [02:52<10:53, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8886 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 9/36 [03:15<10:32, 23.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8945 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  28%|██▊       | 10/36 [03:44<10:50, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8945 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  31%|███       | 11/36 [04:17<11:26, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8939 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 12/36 [04:48<11:27, 28.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8939 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  36%|███▌      | 13/36 [05:17<11:00, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8865 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  39%|███▉      | 14/36 [05:49<10:51, 29.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8865 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 15/36 [06:23<10:50, 30.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8931 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  44%|████▍     | 16/36 [06:57<10:36, 31.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8931 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  47%|████▋     | 17/36 [07:35<10:41, 33.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8936 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 18/36 [08:17<10:50, 36.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8936 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  53%|█████▎    | 19/36 [08:37<08:51, 31.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8808 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  56%|█████▌    | 20/36 [09:00<07:43, 28.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8808 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 21/36 [09:24<06:51, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8839 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  61%|██████    | 22/36 [09:47<06:05, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8839 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  64%|██████▍   | 23/36 [10:16<05:52, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8850 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 24/36 [10:46<05:35, 27.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8850 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  69%|██████▉   | 25/36 [11:29<05:56, 32.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8954 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  72%|███████▏  | 26/36 [12:12<05:54, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8954 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 27/36 [13:02<06:00, 40.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8965 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  78%|███████▊  | 28/36 [13:57<05:55, 44.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8965 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  81%|████████  | 29/36 [15:05<06:00, 51.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8980 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 30/36 [16:16<05:43, 57.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8980 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  86%|████████▌ | 31/36 [17:22<05:00, 60.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8916 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  89%|████████▉ | 32/36 [18:30<04:09, 62.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8916 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 33/36 [19:48<03:21, 67.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8943 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  94%|█████████▍| 34/36 [21:06<02:20, 70.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8943 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  97%|█████████▋| 35/36 [22:42<01:18, 78.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8960 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 36/36 [24:23<00:00, 40.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8960 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n",
      "Best Overall Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.8980\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9347\n",
      "Final Accuracy: 0.9347, Precision: 0.9299, Recall: 0.9403\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.1259\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0838\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.0615\n",
      "Feature: original_firstorder_Mean, Importance: 0.0599\n",
      "Feature: original_firstorder_Median, Importance: 0.0583\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0507\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0368\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0301\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0293\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0287\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0234\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0200\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0142\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0134\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0122\n",
      "Feature: original_firstorder_Variance, Importance: 0.0112\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0110\n",
      "Feature: original_firstorder_Energy, Importance: 0.0109\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0108\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0107\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0106\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0096\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0085\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0083\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0082\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0077\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0073\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0072\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0067\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0066\n",
      "Feature: original_glcm_MCC, Importance: 0.0064\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0063\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0062\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0060\n",
      "Feature: original_glcm_Correlation, Importance: 0.0059\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0058\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0056\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0056\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0055\n",
      "Feature: original_glcm_Imc1, Importance: 0.0054\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0054\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0053\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0052\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0050\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0049\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0044\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0044\n",
      "Feature: original_glcm_Imc2, Importance: 0.0044\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0043\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0043\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0042\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0042\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0039\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0039\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0039\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0037\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0036\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0033\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0032\n",
      "Feature: original_glcm_Id, Importance: 0.0032\n",
      "Feature: original_glcm_Idm, Importance: 0.0031\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0030\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0029\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0028\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0028\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0028\n",
      "Feature: original_firstorder_Range, Importance: 0.0027\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0026\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0026\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0024\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0024\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0024\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0024\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0023\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0023\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0023\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0022\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0022\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0021\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0021\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0021\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0020\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0020\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0019\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0018\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0016\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0015\n",
      "Feature: original_glcm_Idn, Importance: 0.0015\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0014\n",
      "Feature: original_glcm_Idmn, Importance: 0.0013\n",
      "Feature: original_glcm_Contrast, Importance: 0.0013\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0013\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0012\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0009\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0009\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-000245_003-000245_MG_BL_Series-1008_Image-1-0.png', 'hcs_003-000247_003-000247_MG_BL_Series-1005_Image-2-1.png', 'hcs_003-000252_003-000252_MG_TP3_Series-2_Image-1-1.png', 'hcs_003-000257_003-000257_MG_BL_Series-1010_Image-3-1.png', 'hcs_003-000299_003-000299_MG_BL_Series-4_Image-1-1.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2261 (80.84%), Test size: 536 rows (19.16%)\n",
      "Class distribution in train_df: [0: 1130 (49.98%), 1: 1131 (50.02%)] | test_df: [0: 268 (50.00%), 1: 268 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 430 rows (19.02%) | Fold 2: 448 rows (19.81%) | Fold 3: 428 rows (18.93%) | Fold 4: 496 rows (21.94%) | Fold 5: 459 rows (20.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:43<07:57, 43.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8778 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [01:11<05:42, 34.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8782 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [01:42<04:57, 33.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8662 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [02:09<04:03, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8653 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [03:05<04:36, 39.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8791 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 6/12 [03:33<03:34, 35.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8782 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [04:07<02:56, 35.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8662 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [04:32<02:07, 31.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8653 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [05:31<02:01, 40.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8791 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [06:00<01:13, 36.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8782 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [06:31<00:35, 35.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8662 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [06:54<00:00, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8653 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.01\n",
      "Best Overall Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n",
      "Best areaUnderROC: 0.8791\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial columns: 119, number of feature columns: 99\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.9086\n",
      "Final Accuracy: 0.9086, Precision: 0.8842, Recall: 0.9403\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000071_001-000071_MG_TP3_Series-4_Image-1-0.png', 'hcs_003-000242_003-000242_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000245_003-000245_MG_BL_Series-1008_Image-1-0.png', 'hcs_003-000245_003-000245_MG_BL_Series-1008_Image-2-0.png', 'hcs_003-000277_003-000277_MG_BL_Series-3_Image-1-0.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4,  1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2261 (80.84%), Test size: 536 rows (19.16%)\n",
      "Class distribution in train_df: [0: 1130 (49.98%), 1: 1131 (50.02%)] | test_df: [0: 268 (50.00%), 1: 268 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 430 rows (19.02%) | Fold 2: 448 rows (19.81%) | Fold 3: 428 rows (18.93%) | Fold 4: 496 rows (21.94%) | Fold 5: 459 rows (20.30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/1 [00:00<?, ?it/s]2024-09-20 17:59:30,111 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 17:59:37,630 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 17:59:44,669 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 17:59:49,984 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 17:59:55,786 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 18:00:01,019 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 18:00:06,899 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 18:00:12,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 18:00:17,979 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 18:00:23,187 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 1/1 [00:59<00:00, 59.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.8806 | Evaluating Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best Overall Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.8806\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-20 18:00:27,233 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 18:00:32,705 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.9104\n",
      "Final Accuracy: 0.9104, Precision: 0.9074, Recall: 0.9142\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['hcs_003-000245_003-000245_MG_BL_Series-1008_Image-1-0.png', 'hcs_003-000247_003-000247_MG_BL_Series-1005_Image-1-1.png', 'hcs_003-000247_003-000247_MG_BL_Series-1005_Image-2-1.png', 'hcs_003-000252_003-000252_MG_TP3_Series-2_Image-1-1.png', 'hcs_003-000257_003-000257_MG_BL_Series-1010_Image-3-1.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [6]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 128 - with full mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'features_128_full_mask.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2260 (80.77%), Test size: 538 rows (19.23%)\n",
      "Class distribution in train_df: [0: 1130 (50.00%), 1: 1130 (50.00%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 522 rows (23.10%) | Fold 2: 426 rows (18.85%) | Fold 3: 420 rows (18.58%) | Fold 4: 474 rows (20.97%) | Fold 5: 418 rows (18.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:19<02:13, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7558 | Evaluating Parameters: maxDepth: 5, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [00:41<02:07, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7671 | Evaluating Parameters: maxDepth: 5, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [00:58<01:36, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7288 | Evaluating Parameters: maxDepth: 10, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 4/8 [01:22<01:23, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7387 | Evaluating Parameters: maxDepth: 10, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [01:41<01:01, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7058 | Evaluating Parameters: maxDepth: 15, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [02:04<00:42, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7144 | Evaluating Parameters: maxDepth: 15, maxBins: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [02:28<00:22, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7020 | Evaluating Parameters: maxDepth: 20, maxBins: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 8/8 [02:48<00:00, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7129 | Evaluating Parameters: maxDepth: 20, maxBins: 64\n",
      "Best Overall Parameters: maxDepth: 5, maxBins: 64\n",
      "Best areaUnderROC: 0.7671\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7807\n",
      "Final Accuracy: 0.7807, Precision: 0.8159, Recall: 0.7249\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.7645\n",
      "Feature: original_firstorder_Variance, Importance: 0.0742\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0277\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0240\n",
      "Feature: original_glcm_Correlation, Importance: 0.0164\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0163\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0159\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0108\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0087\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0084\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0073\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0068\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0039\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0038\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0033\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0031\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0029\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0020\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "Feature: original_firstorder_Energy, Importance: 0.0000\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0000\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0000\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0000\n",
      "Feature: original_firstorder_Mean, Importance: 0.0000\n",
      "Feature: original_firstorder_Median, Importance: 0.0000\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0000\n",
      "Feature: original_firstorder_Range, Importance: 0.0000\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.0000\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0000\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0000\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0000\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0000\n",
      "Feature: original_glcm_Contrast, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0000\n",
      "Feature: original_glcm_Id, Importance: 0.0000\n",
      "Feature: original_glcm_Idm, Importance: 0.0000\n",
      "Feature: original_glcm_Idmn, Importance: 0.0000\n",
      "Feature: original_glcm_Idn, Importance: 0.0000\n",
      "Feature: original_glcm_Imc1, Importance: 0.0000\n",
      "Feature: original_glcm_Imc2, Importance: 0.0000\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0000\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0000\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0000\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_MCC, Importance: 0.0000\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0000\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0000\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0000\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0000\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0000\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0000\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0000\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0000\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0000\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0000\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0000\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-1.png', 'hcs_003-000107_003-000107_MG_BL_Series-1001_Image-1001-0.png']\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(labelCol = \"class\", featuresCol = \"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(decision_tree.maxDepth, [5, 10, 15, 20]) \\\n",
    "    .addGrid(decision_tree.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(decision_tree, file_name, param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2260 (80.77%), Test size: 538 rows (19.23%)\n",
      "Class distribution in train_df: [0: 1130 (50.00%), 1: 1130 (50.00%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 522 rows (23.10%) | Fold 2: 426 rows (18.85%) | Fold 3: 420 rows (18.58%) | Fold 4: 474 rows (20.97%) | Fold 5: 418 rows (18.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   3%|▎         | 1/36 [00:17<10:26, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7757 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   6%|▌         | 2/36 [00:39<11:21, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7757 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 3/36 [00:57<10:26, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7761 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  11%|█         | 4/36 [01:19<10:53, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7761 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  14%|█▍        | 5/36 [01:40<10:30, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7782 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 6/36 [02:02<10:27, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7782 | Evaluating Parameters: numTrees: 50, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  19%|█▉        | 7/36 [02:31<11:26, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7727 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  22%|██▏       | 8/36 [02:58<11:31, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7727 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 9/36 [03:29<11:59, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7718 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  28%|██▊       | 10/36 [04:02<12:27, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7718 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  31%|███       | 11/36 [04:44<13:39, 32.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7709 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 12/36 [05:28<14:28, 36.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7709 | Evaluating Parameters: numTrees: 50, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  36%|███▌      | 13/36 [06:14<15:03, 39.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7702 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  39%|███▉      | 14/36 [07:06<15:44, 42.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7702 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 15/36 [08:00<16:12, 46.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7707 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  44%|████▍     | 16/36 [08:58<16:34, 49.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7707 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  47%|████▋     | 17/36 [10:12<18:05, 57.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7626 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 18/36 [11:19<18:04, 60.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7626 | Evaluating Parameters: numTrees: 50, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  53%|█████▎    | 19/36 [11:43<13:54, 49.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7781 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  56%|█████▌    | 20/36 [12:10<11:20, 42.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7781 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 21/36 [12:41<09:46, 39.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7769 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  61%|██████    | 22/36 [13:11<08:31, 36.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7769 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  64%|██████▍   | 23/36 [13:46<07:45, 35.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7783 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 24/36 [14:19<07:01, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7783 | Evaluating Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  69%|██████▉   | 25/36 [15:21<07:54, 43.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7734 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  72%|███████▏  | 26/36 [16:23<08:06, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7734 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 27/36 [17:35<08:21, 55.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7701 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  78%|███████▊  | 28/36 [18:47<08:05, 60.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7701 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  81%|████████  | 29/36 [20:31<08:36, 73.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7753 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 30/36 [22:17<08:19, 83.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7753 | Evaluating Parameters: numTrees: 150, maxDepth: 10, maxBins: 128, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  86%|████████▌ | 31/36 [23:51<07:12, 86.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7700 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  89%|████████▉ | 32/36 [25:23<05:52, 88.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7700 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 32, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 33/36 [27:18<04:48, 96.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7670 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  94%|█████████▍| 34/36 [29:12<03:23, 101.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7670 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 64, featureSubsetStrategy: sqrt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  97%|█████████▋| 35/36 [31:58<02:00, 120.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7679 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 36/36 [34:43<00:00, 57.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7679 | Evaluating Parameters: numTrees: 150, maxDepth: 15, maxBins: 128, featureSubsetStrategy: sqrt\n",
      "Best Overall Parameters: numTrees: 150, maxDepth: 5, maxBins: 128, featureSubsetStrategy: auto\n",
      "Best areaUnderROC: 0.7783\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7844\n",
      "Final Accuracy: 0.7844, Precision: 0.7823, Recall: 0.7881\n",
      "\n",
      "Sorted Feature Importances:\n",
      "Feature: original_firstorder_90Percentile, Importance: 0.1212\n",
      "Feature: original_firstorder_RootMeanSquared, Importance: 0.1071\n",
      "Feature: original_firstorder_MeanAbsoluteDeviation, Importance: 0.0766\n",
      "Feature: original_firstorder_Mean, Importance: 0.0662\n",
      "Feature: original_firstorder_TotalEnergy, Importance: 0.0642\n",
      "Feature: original_firstorder_Energy, Importance: 0.0586\n",
      "Feature: original_firstorder_Variance, Importance: 0.0561\n",
      "Feature: diagnostics_Image-original_Mean, Importance: 0.0414\n",
      "Feature: original_firstorder_Median, Importance: 0.0369\n",
      "Feature: original_firstorder_RobustMeanAbsoluteDeviation, Importance: 0.0342\n",
      "Feature: original_firstorder_InterquartileRange, Importance: 0.0315\n",
      "Feature: original_firstorder_Skewness, Importance: 0.0256\n",
      "Feature: original_glszm_SizeZoneNonUniformity, Importance: 0.0202\n",
      "Feature: original_glszm_GrayLevelNonUniformity, Importance: 0.0191\n",
      "Feature: original_firstorder_Kurtosis, Importance: 0.0170\n",
      "Feature: original_gldm_SmallDependenceLowGrayLevelEmphasis, Importance: 0.0121\n",
      "Feature: original_glszm_LargeAreaEmphasis, Importance: 0.0115\n",
      "Feature: original_glszm_ZoneVariance, Importance: 0.0083\n",
      "Feature: original_firstorder_10Percentile, Importance: 0.0072\n",
      "Feature: original_glrlm_ShortRunLowGrayLevelEmphasis, Importance: 0.0060\n",
      "Feature: original_glcm_Imc1, Importance: 0.0059\n",
      "Feature: original_glcm_Correlation, Importance: 0.0057\n",
      "Feature: original_glcm_ClusterProminence, Importance: 0.0047\n",
      "Feature: original_glcm_Imc2, Importance: 0.0046\n",
      "Feature: original_glcm_MCC, Importance: 0.0045\n",
      "Feature: original_gldm_DependenceVariance, Importance: 0.0044\n",
      "Feature: original_glszm_LargeAreaHighGrayLevelEmphasis, Importance: 0.0041\n",
      "Feature: original_glszm_SmallAreaLowGrayLevelEmphasis, Importance: 0.0040\n",
      "Feature: original_glszm_ZonePercentage, Importance: 0.0040\n",
      "Feature: original_glrlm_ShortRunHighGrayLevelEmphasis, Importance: 0.0039\n",
      "Feature: original_glszm_LargeAreaLowGrayLevelEmphasis, Importance: 0.0038\n",
      "Feature: original_glcm_SumEntropy, Importance: 0.0037\n",
      "Feature: original_gldm_DependenceNonUniformity, Importance: 0.0037\n",
      "Feature: original_gldm_SmallDependenceEmphasis, Importance: 0.0036\n",
      "Feature: original_gldm_LowGrayLevelEmphasis, Importance: 0.0034\n",
      "Feature: original_glcm_ClusterShade, Importance: 0.0033\n",
      "Feature: original_glszm_SmallAreaHighGrayLevelEmphasis, Importance: 0.0033\n",
      "Feature: original_gldm_GrayLevelNonUniformity, Importance: 0.0033\n",
      "Feature: original_glszm_HighGrayLevelZoneEmphasis, Importance: 0.0033\n",
      "Feature: original_glrlm_RunVariance, Importance: 0.0033\n",
      "Feature: original_glszm_ZoneEntropy, Importance: 0.0032\n",
      "Feature: original_glszm_SmallAreaEmphasis, Importance: 0.0031\n",
      "Feature: original_ngtdm_Coarseness, Importance: 0.0030\n",
      "Feature: original_glszm_LowGrayLevelZoneEmphasis, Importance: 0.0030\n",
      "Feature: original_glszm_SizeZoneNonUniformityNormalized, Importance: 0.0029\n",
      "Feature: original_glcm_ClusterTendency, Importance: 0.0029\n",
      "Feature: original_glrlm_GrayLevelVariance, Importance: 0.0028\n",
      "Feature: original_glszm_GrayLevelVariance, Importance: 0.0028\n",
      "Feature: original_gldm_SmallDependenceHighGrayLevelEmphasis, Importance: 0.0027\n",
      "Feature: original_gldm_LargeDependenceLowGrayLevelEmphasis, Importance: 0.0027\n",
      "Feature: original_glrlm_RunLengthNonUniformityNormalized, Importance: 0.0026\n",
      "Feature: original_glrlm_RunEntropy, Importance: 0.0026\n",
      "Feature: original_glcm_SumAverage, Importance: 0.0026\n",
      "Feature: original_glcm_DifferenceEntropy, Importance: 0.0026\n",
      "Feature: original_gldm_HighGrayLevelEmphasis, Importance: 0.0026\n",
      "Feature: original_glcm_DifferenceVariance, Importance: 0.0025\n",
      "Feature: original_glrlm_LongRunHighGrayLevelEmphasis, Importance: 0.0025\n",
      "Feature: original_glrlm_RunLengthNonUniformity, Importance: 0.0024\n",
      "Feature: original_glrlm_LongRunEmphasis, Importance: 0.0024\n",
      "Feature: original_glcm_Autocorrelation, Importance: 0.0023\n",
      "Feature: original_glcm_MaximumProbability, Importance: 0.0023\n",
      "Feature: original_ngtdm_Busyness, Importance: 0.0023\n",
      "Feature: original_gldm_DependenceEntropy, Importance: 0.0021\n",
      "Feature: original_glrlm_GrayLevelNonUniformityNormalized, Importance: 0.0020\n",
      "Feature: original_ngtdm_Contrast, Importance: 0.0019\n",
      "Feature: original_gldm_GrayLevelVariance, Importance: 0.0019\n",
      "Feature: original_glcm_SumSquares, Importance: 0.0019\n",
      "Feature: original_glcm_JointEnergy, Importance: 0.0018\n",
      "Feature: original_glrlm_GrayLevelNonUniformity, Importance: 0.0018\n",
      "Feature: original_glrlm_HighGrayLevelRunEmphasis, Importance: 0.0018\n",
      "Feature: original_glrlm_LongRunLowGrayLevelEmphasis, Importance: 0.0017\n",
      "Feature: original_gldm_LargeDependenceHighGrayLevelEmphasis, Importance: 0.0016\n",
      "Feature: original_glszm_GrayLevelNonUniformityNormalized, Importance: 0.0016\n",
      "Feature: original_glrlm_LowGrayLevelRunEmphasis, Importance: 0.0016\n",
      "Feature: original_gldm_DependenceNonUniformityNormalized, Importance: 0.0016\n",
      "Feature: original_glrlm_ShortRunEmphasis, Importance: 0.0015\n",
      "Feature: original_glcm_InverseVariance, Importance: 0.0014\n",
      "Feature: original_glcm_JointEntropy, Importance: 0.0013\n",
      "Feature: original_firstorder_Uniformity, Importance: 0.0012\n",
      "Feature: original_glcm_JointAverage, Importance: 0.0011\n",
      "Feature: original_ngtdm_Strength, Importance: 0.0010\n",
      "Feature: original_glcm_Idn, Importance: 0.0009\n",
      "Feature: original_gldm_LargeDependenceEmphasis, Importance: 0.0009\n",
      "Feature: original_glcm_Idmn, Importance: 0.0009\n",
      "Feature: original_firstorder_Entropy, Importance: 0.0009\n",
      "Feature: original_glcm_Contrast, Importance: 0.0009\n",
      "Feature: original_glcm_Idm, Importance: 0.0008\n",
      "Feature: original_glcm_Id, Importance: 0.0008\n",
      "Feature: original_ngtdm_Complexity, Importance: 0.0007\n",
      "Feature: original_glrlm_RunPercentage, Importance: 0.0007\n",
      "Feature: original_firstorder_Maximum, Importance: 0.0006\n",
      "Feature: original_firstorder_Minimum, Importance: 0.0005\n",
      "Feature: original_glcm_DifferenceAverage, Importance: 0.0003\n",
      "Feature: original_firstorder_Range, Importance: 0.0003\n",
      "Feature: diagnostics_Image-original_Dimensionality, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Minimum, Importance: 0.0000\n",
      "Feature: diagnostics_Image-original_Maximum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VoxelNum, Importance: 0.0000\n",
      "Feature: diagnostics_Mask-original_VolumeNum, Importance: 0.0000\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-1.png']\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up parameter grid for hyperparameter tuning\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(random_forest.numTrees, [50, 150]) \\\n",
    "    .addGrid(random_forest.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(random_forest.maxBins, [32, 64, 128]) \\\n",
    "    .addGrid(random_forest.featureSubsetStrategy, ['auto', 'sqrt']) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(random_forest, file_name, rf_param_grid, is_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2260 (80.77%), Test size: 538 rows (19.23%)\n",
      "Class distribution in train_df: [0: 1130 (50.00%), 1: 1130 (50.00%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 522 rows (23.10%) | Fold 2: 426 rows (18.85%) | Fold 3: 420 rows (18.58%) | Fold 4: 474 rows (20.97%) | Fold 5: 418 rows (18.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   8%|▊         | 1/12 [00:39<07:09, 39.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7765 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  17%|█▋        | 2/12 [01:04<05:10, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7746 | Evaluating Parameters: maxIter: 100, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  25%|██▌       | 3/12 [01:34<04:34, 30.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7734 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  33%|███▎      | 4/12 [01:54<03:30, 26.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7752 | Evaluating Parameters: maxIter: 100, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  42%|████▏     | 5/12 [02:41<03:57, 33.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7767 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  50%|█████     | 6/12 [03:07<03:06, 31.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7746 | Evaluating Parameters: maxIter: 500, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  58%|█████▊    | 7/12 [03:37<02:34, 30.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7734 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  67%|██████▋   | 8/12 [03:57<01:49, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7752 | Evaluating Parameters: maxIter: 500, regParam: 0.1, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  75%|███████▌  | 9/12 [04:50<01:46, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7767 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  83%|████████▎ | 10/12 [05:11<01:02, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7746 | Evaluating Parameters: maxIter: 1000, regParam: 0.01, tol: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:  92%|█████████▏| 11/12 [05:43<00:31, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7734 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning: 100%|██████████| 12/12 [06:08<00:00, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7752 | Evaluating Parameters: maxIter: 1000, regParam: 0.1, tol: 0.01\n",
      "Best Overall Parameters: maxIter: 500, regParam: 0.01, tol: 0.0001\n",
      "Best areaUnderROC: 0.7767\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial columns: 119, number of feature columns: 99\n",
      "Final Model Evaluation on Test Data areaUnderROC: 0.8086\n",
      "Final Accuracy: 0.8086, Precision: 0.7923, Recall: 0.8364\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000107_003-000107_MG_BL_Series-1001_Image-1001-1.png']\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC with Standard Scaler\n",
    "svc = LinearSVC(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "svc_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svc.maxIter, [100, 500, 1000]) \\\n",
    "    .addGrid(svc.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(svc.tol, [1e-4,  1e-2]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function with the XGBoost classifier\n",
    "model = main(svc, file_name, svc_param_grid, is_tree=False, use_standard_scaler=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      " Setting up\n",
      "===========================================================================\n",
      "\n",
      "No overlapping patients between training and test sets.\n",
      "Training size: 2260 (80.77%), Test size: 538 rows (19.23%)\n",
      "Class distribution in train_df: [0: 1130 (50.00%), 1: 1130 (50.00%)] | test_df: [0: 269 (50.00%), 1: 269 (50.00%)]\n",
      "\n",
      "===========================================================================\n",
      " Hyperparameter tunning\n",
      "===========================================================================\n",
      "\n",
      "Fold 1: 522 rows (23.10%) | Fold 2: 426 rows (18.85%) | Fold 3: 420 rows (18.58%) | Fold 4: 474 rows (20.97%) | Fold 5: 418 rows (18.50%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyperparameter Tuning:   0%|          | 0/8 [00:00<?, ?it/s]2024-09-20 00:16:18,898 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:16:27,804 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:16:33,157 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:16:37,906 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:16:43,257 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:16:48,030 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:16:53,298 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:16:58,110 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:17:03,430 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:17:08,272 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  12%|█▎        | 1/8 [00:56<06:36, 56.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7759 | Evaluating Parameters: max_depth: 3, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:17:14,879 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:17:20,527 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:17:27,560 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:17:33,193 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:17:40,073 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:17:45,717 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:17:52,648 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:17:58,459 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:18:05,520 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 3, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:18:11,277 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  25%|██▌       | 2/8 [01:59<06:03, 60.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7785 | Evaluating Parameters: max_depth: 3, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:18:18,326 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:18:24,234 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:18:29,746 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:18:35,093 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:18:41,363 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:18:47,306 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:18:54,316 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:19:00,315 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:19:07,247 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:19:13,304 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  38%|███▊      | 3/8 [03:02<05:06, 61.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7696 | Evaluating Parameters: max_depth: 6, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:19:20,341 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:19:26,696 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:19:33,703 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:19:40,444 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:19:47,442 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:19:53,878 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:20:00,859 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:20:07,326 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:20:14,488 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 6, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:20:20,889 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  50%|█████     | 4/8 [04:09<04:14, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7663 | Evaluating Parameters: max_depth: 6, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:20:27,913 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:20:34,522 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:20:41,547 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:20:48,258 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:20:55,302 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:21:01,893 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:21:08,583 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:21:15,339 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:21:22,305 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:21:28,971 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  62%|██████▎   | 5/8 [05:17<03:16, 65.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7787 | Evaluating Parameters: max_depth: 9, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:21:36,049 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:21:43,543 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:21:50,555 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:21:58,032 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:22:05,082 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:22:12,573 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:22:19,576 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:22:27,096 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:22:34,170 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:22:41,308 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  75%|███████▌  | 6/8 [06:30<02:15, 67.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7705 | Evaluating Parameters: max_depth: 9, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:22:48,437 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:22:55,555 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:23:02,610 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:23:09,909 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:23:17,000 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:23:24,061 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:23:31,041 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:23:38,091 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:23:45,131 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:23:52,303 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning:  88%|████████▊ | 7/8 [07:41<01:08, 68.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7670 | Evaluating Parameters: max_depth: 12, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 00:23:59,541 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:24:07,582 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:24:15,086 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:24:23,210 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:24:30,218 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:24:38,329 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:24:44,959 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:24:53,025 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "2024-09-20 00:25:00,107 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 12, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:25:08,459 INFO XGBoost-PySpark: _fit Finished xgboost training!\n",
      "Hyperparameter Tuning: 100%|██████████| 8/8 [08:57<00:00, 67.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average areaUnderROC: 0.7717 | Evaluating Parameters: max_depth: 12, n_estimators: 100, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best Overall Parameters: max_depth: 9, n_estimators: 50, learning_rate: 0.1, subsample: 0.8, colsample_bytree: 0.8\n",
      "Best areaUnderROC: 0.7787\n",
      "\n",
      "===========================================================================\n",
      " Testing model on test dataset\n",
      "===========================================================================\n",
      "\n",
      "Number of initial columns: 119, number of feature columns: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-09-20 00:25:13,469 INFO XGBoost-PySpark: _fit Running xgboost-2.1.1 on 1 workers with\n",
      "\tbooster params: {'colsample_bytree': 0.8, 'device': 'cpu', 'learning_rate': 0.1, 'max_depth': 9, 'objective': 'binary:logistic', 'subsample': 0.8, 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 50}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-09-20 00:25:20,424 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation on Test Data areaUnderROC: 0.7807\n",
      "Final Accuracy: 0.7807, Precision: 0.7849, Recall: 0.7732\n",
      "\n",
      "First 5 names of wrongly classified rows:\n",
      "['auth_001-000084_001-000084_MG_BL_Series-3_Image-1-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1001_Image-1001-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1002_Image-1002-1.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-0.png', 'hcs_003-000029_003-000029_MG_BL_Series-1003_Image-1003-1.png']\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = SparkXGBClassifier(label_col=\"class\", features_col=\"features\", use_gpu=False) \n",
    "\n",
    "# Set up the parameter grid for hyperparameter tuning\n",
    "xgb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(xgb_classifier.max_depth, [3, 6, 9, 12]) \\\n",
    "    .addGrid(xgb_classifier.n_estimators, [50, 100]) \\\n",
    "    .addGrid(xgb_classifier.learning_rate, [0.1]) \\\n",
    "    .addGrid(xgb_classifier.subsample, [0.8]) \\\n",
    "    .addGrid(xgb_classifier.colsample_bytree, [0.8]) \\\n",
    "    .build()\n",
    "\n",
    "# Call the main function to train and evaluate the model\n",
    "model = main(xgb_classifier, file_name, xgb_param_grid, is_tree=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
